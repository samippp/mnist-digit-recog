{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf712d6d-c2ee-4807-a690-e21363b3153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44b3b11-e51f-4168-b8f7-097d508f71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z): #relu func for normalization at the hidden layers\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return exp_Z / exp_Z.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01201907-4ca2-44d0-a943-2cbe1481e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size, hidden_size1, hidden_size2, output_size):\n",
    "    w1 = np.random.randn(input_size, hidden_size1) * 0.01\n",
    "    b1 = np.zeros((1, hidden_size1))\n",
    "    w2 = np.random.randn(hidden_size1,hidden_size2) * 0.01\n",
    "    b2 = np.zeros((1, hidden_size2))\n",
    "    w3 = np.random.randn(hidden_size2, output_size) * 0.01\n",
    "    b3 = np.zeros((1,output_size))\n",
    "    return w1,b1,w2,b2,w3,b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8f189c-7868-4ece-9ae0-daa139ff72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, w1, b1, w2, b2, w3, b3):\n",
    "    z1 = np.dot(x, w1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, w2) + b2   \n",
    "    a2 = relu(z2)\n",
    "\n",
    "    z3 = np.dot(a2, w3) + b3  \n",
    "    a3 = softmax(z3)\n",
    "\n",
    "    return a1, a2, a3, z1, z2, z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5150235-560d-4fae-9713-3938e8ab447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_reLu(y):\n",
    "    return y > 0\n",
    "\n",
    "def back_prop(x,y,a1,a2,a3,w2,w3,z1,z2):\n",
    "    m = y.shape[0]\n",
    "    dC3 = a3 - y\n",
    "    dW3 = a2.T.dot(dC3) / m\n",
    "    dB3 = 1 / m * np.sum(dC3, axis=0, keepdims=True)\n",
    "    \n",
    "    dC2 = dC3.dot(w3.T) * deriv_reLu(z2)\n",
    "    dW2 = 1 / m * a1.T.dot(dC2)\n",
    "    dB2 = 1 / m * np.sum(dC2, axis=0, keepdims=True)\n",
    "\n",
    "    dC1 = dC2.dot(w2.T) * deriv_reLu(z1)\n",
    "    dW1 = 1 / m * x.T.dot(dC1)\n",
    "    dB1 = 1 / m * np.sum(dC1, axis=0, keepdims=True)\n",
    "    return dW3, dB3, dW2, dB2, dW1, dB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fe2541-5bbb-4510-ad99-d1a2910c44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(w1,b1,w2,b2,w3,b3,dW3, dB3, dW2, dB2, dW1, dB1, learning_rate):\n",
    "    w1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * dB1\n",
    "    w2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * dB2\n",
    "    w3 -= learning_rate * dW3\n",
    "    b3 -= learning_rate * dB3\n",
    "    return (w1,b2,w2,b2,w3,b3)\n",
    "\n",
    "def predict(predictions):\n",
    "    return np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c899b5c7-9712-41e7-9b86-cd7781d12c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(Y, A3):#https://www.parasdahal.com/softmax-crossentropy\n",
    "    m = Y.shape[0]\n",
    "    log_likelihood = -np.log(A3[range(m), Y.argmax(axis=1)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "def batch_gradient_descent(x, y, iterations, learning_rate, init):\n",
    "    w1,b1,w2,b2,w3,b3 = init\n",
    "    for i in range(iterations):\n",
    "        a1,a2,a3,z1,z2,z3 = forward_prop(x,w1, b1, w2, b2, w3, b3)\n",
    "        loss = compute_loss(y, a3)\n",
    "        dW3, dB3, dW2, dB2, dW1, dB1 = back_prop(x,y,a1,a2,a3,w2,w3,z1,z2)\n",
    "\n",
    "        w1,b2,w2,b2,w3,b3 = update_params(w1,b1,w2,b2,w3,b3,dW3,dB3,dW2,dB2,dW1,dB1, learning_rate)\n",
    "        if( i % 10 == 0):\n",
    "            print(\"Iteration\", i)\n",
    "            print(\"Loss: \",  loss)\n",
    "\n",
    "    return w1,b1,w2,b2,w3,b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f89a984-3ef0-4f7b-bb4b-5c2b8da712ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Loss:  2.3025819510391643\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m10\u001b[39m)[y_test]\n\u001b[0;32m      7\u001b[0m init \u001b[38;5;241m=\u001b[39m init_params(\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m new_params \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m new_params \u001b[38;5;241m=\u001b[39m batch_gradient_descent(x_train,y_train,\u001b[38;5;241m250\u001b[39m,\u001b[38;5;241m0.1\u001b[39m, new_params)\n\u001b[0;32m     11\u001b[0m w1,b1,w2,b2,w3,b3 \u001b[38;5;241m=\u001b[39m new_params\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36mbatch_gradient_descent\u001b[1;34m(x, y, iterations, learning_rate, init)\u001b[0m\n\u001b[0;32m      8\u001b[0m w1,b1,w2,b2,w3,b3 \u001b[38;5;241m=\u001b[39m init\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m---> 10\u001b[0m     a1,a2,a3,z1,z2,z3 \u001b[38;5;241m=\u001b[39m \u001b[43mforward_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m compute_loss(y, a3)\n\u001b[0;32m     12\u001b[0m     dW3, dB3, dW2, dB2, dW1, dB1 \u001b[38;5;241m=\u001b[39m back_prop(x,y,a1,a2,a3,w2,w3,z1,z2)\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mforward_prop\u001b[1;34m(x, w1, b1, w2, b2, w3, b3)\u001b[0m\n\u001b[0;32m      7\u001b[0m batch_norm_std1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(a1,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m a1_normalize \u001b[38;5;241m=\u001b[39m (a1 \u001b[38;5;241m-\u001b[39m batch_norm_m1) \u001b[38;5;241m/\u001b[39m batch_norm_std1\n\u001b[1;32m---> 11\u001b[0m z2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b2   \n\u001b[0;32m     12\u001b[0m a2 \u001b[38;5;241m=\u001b[39m relu(z2)\n\u001b[0;32m     14\u001b[0m batch_norm_m2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(a2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\core\\multiarray.py:741\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;124;03m    result_type(*arrays_and_dtypes)\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    736\u001b[0m \n\u001b[0;32m    737\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays_and_dtypes\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mdot)\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdot\u001b[39m(a, b, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    743\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    dot(a, b, out=None)\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    829\u001b[0m \n\u001b[0;32m    830\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b, out)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 784) / 255.0  # Flatten and normalize\n",
    "x_test = x_test.reshape(x_test.shape[0], 784) / 255.0\n",
    "y_train = np.eye(10)[y_train]  # One-hot encoding\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "init = init_params(784, 128, 64, 10)\n",
    "\n",
    "new_params = batch_gradient_descent(x_train,y_train,70,0.6, init)\n",
    "new_params = batch_gradient_descent(x_train,y_train,250,0.1, new_params)\n",
    "w1,b1,w2,b2,w3,b3 = new_params\n",
    "a1,a2,a3, z1,z2,z3 = forward_prop(x_test,w1,b1,w2,b2,w3,b3)\n",
    "predictions = np.argmax(a3, axis=1)\n",
    "accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d82b2a-a432-436d-b835-a690f39c855a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37334cb1-e151-4df0-8a23-d9f25055eb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de6b88-6c9d-453b-8f69-46e060e5559c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
